{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "486550f0-68a5-4311-acfd-68f449402757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Ruta del archivo CSV\n",
    "ruta_csv = r'C:\\Users\\marib\\OneDrive\\Escritorio\\295\\data_ioc_1min_2023_2024\\pich_prs.csv'\n",
    "# Lectura del archivo CSV en un DataFrame\n",
    "csv = pd.read_csv(ruta_csv)\n",
    "\n",
    "csv['fecha'] = pd.to_datetime(csv['fecha']) # Asegurarse de que la fecha este en formato DateTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5796d62-2bca-45dc-8437-a5fdf9eb5e34",
   "metadata": {},
   "source": [
    "## Filtro temporal y de outliers de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e48144e-ab9c-42b5-b1e9-4d4dbfc84c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos desde julio de 2023 hasta la actualidad\n",
    "start_date = '2023-07-01 00:01:00'\n",
    "end_date = pd.to_datetime('2024-09-30 23:59:00')\n",
    "csv_filtered = csv[(csv['fecha'] >= start_date) & (csv['fecha'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2015cc3f-b8dd-4e6d-822a-1dd0441f91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marib\\AppData\\Local\\Temp\\ipykernel_12888\\395208371.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv_filtered['prs(m)'] = csv_filtered['prs(m)'].apply(lambda x: np.nan if not rango_min_prs <= x <= rango_max_prs else x)\n"
     ]
    }
   ],
   "source": [
    "# Limpieza data de outliers problematicos\n",
    "rango_min_prs = 1.0  # valor mínimo permitido\n",
    "rango_max_prs = 4.0  # valor máximo permitido\n",
    "\n",
    "# Reemplazar los valores fuera del rango con NaN\n",
    "csv_filtered['prs(m)'] = csv_filtered['prs(m)'].apply(lambda x: np.nan if not rango_min_prs <= x <= rango_max_prs else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "396bf6de-a3e3-49e8-ad6b-111b11ab6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "# Graficar los datos del archivo CSV\n",
    "#plt.xlabel('Fecha', fontsize=20) # Label de x\n",
    "plt.ylabel('Nivel del Mar [m]', fontsize=20) # Label de y\n",
    "plt.plot(csv_filtered['fecha'], csv_filtered['prs(m)'], color='black', label='NM[m]') # Ploteo de datos\n",
    "plt.xticks(fontsize=18)                 \n",
    "plt.yticks(fontsize=18) \n",
    "\n",
    "# Añadir leyenda\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right', fontsize=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.title('Sea Level Pichidangui (july 2023-september 2024)', fontsize=20) # titulo\n",
    "plt.show() # Mostrar figura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949eead-6dbd-4dcb-b2d1-5ca1edfaf972",
   "metadata": {},
   "source": [
    "## Cálculo de armonicos gravitacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76ff9c79-54a7-420d-83c3-abfe08152012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utide\n",
    "import utide\n",
    "# Definimos los vectores de tiempo y nivel del mar \n",
    "t=csv_filtered['fecha']\n",
    "u=csv_filtered['prs(m)']-csv['prs(m)'].mean() # Nivel del mar al rededor del promedio\n",
    "# Cálculo de los coeficientes armónicos de la marea\n",
    "coef = utide.solve(t,u,\n",
    "    lat=-32.7756,\n",
    "    method=\"ols\",\n",
    "    conf_int=\"MC\",\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4328de3-33eb-4862-9720-6c10487ab4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Armonico  Amplitud        Fase  Porcentaje de Energia\n",
      "0        M2  0.435490   60.219877           7.083914e+01\n",
      "1        K1  0.157724   41.973856           9.292023e+00\n",
      "2        S2  0.149004   82.326926           8.293072e+00\n",
      "3        O1  0.103614  356.125652           4.010107e+00\n",
      "4        N2  0.098815   28.335329           3.647256e+00\n",
      "..      ...       ...         ...                    ...\n",
      "62      MS4  0.000122  233.413403           5.571899e-06\n",
      "63     MSK6  0.000087  274.282566           2.832002e-06\n",
      "64     3MK7  0.000079  286.763331           2.304618e-06\n",
      "65      SN4  0.000063  167.953828           1.494317e-06\n",
      "66       M8  0.000011  104.067500           4.674403e-08\n",
      "\n",
      "[67 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creación de tabla de coeficientes\n",
    "nombres = coef.get('name') # Nombre del armónico\n",
    "amplitud = coef.get('A') # Amplitud del armónico\n",
    "porcentaje_de_energia = coef.get('PE') # Porcentaje de energía del armónico\n",
    "fase = coef.get('g') # Fase del armónico\n",
    "\n",
    "# Crear un DataFrame con pandas\n",
    "df_armonicos = pd.DataFrame({\n",
    "    'Armonico': nombres,\n",
    "    'Amplitud': amplitud,\n",
    "    'Fase': fase,\n",
    "    'Porcentaje de Energia': porcentaje_de_energia\n",
    "})\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(df_armonicos)\n",
    "# Guardar la tabla como CSV\n",
    "df_armonicos.to_csv('armonicos_pich.csv', index=False)\n",
    "# Reconstrucción de la marea\n",
    "tide = utide.reconstruct(t, coef, verbose=False)\n",
    "# Only M2 K1 S2\n",
    "m2_tide_data = utide.reconstruct(t, coef, verbose=False, constit = ['M2', 'K1', 'S2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70662f13-149f-4f6b-acc3-84ee3fdfb0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0322586246617043\n"
     ]
    }
   ],
   "source": [
    "# Dataframe con datos de la reconstrucción\n",
    "df_tide = pd.DataFrame({\n",
    "    'Datos Originales Pichidangui': u,\n",
    "    'Reconstruccion Pichidangui': tide.h,\n",
    "    'M2 Pich': m2_tide_data.h,\n",
    "    'Residuo Pichidangui': u-tide.h,       # Residuo entre la marea original y la marea gravitacional\n",
    "    'fecha': t,\n",
    "})\n",
    "\n",
    "# Guardar los datos como CSV\n",
    "df_tide.to_csv('reconstrucion_residuo_pich.csv', index=False)\n",
    "# Cálculo de la proporción de variancias de los residuos y datos originales\n",
    "print(df_tide['Residuo Pichidangui'].var()/df_tide['Datos Originales Pichidangui'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ae248a0-df4a-470d-a480-2806c097de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los armónicos\n",
    "#plt.xlabel('Fecha', fontsize=20) # Label de x\n",
    "plt.ylabel('Nivel de la Marea [m]', fontsize=20) # Label de y\n",
    "plt.plot(t, tide.h, color='navy', label='Nivel de la Marea [m]') # Ploteo de datos\n",
    "plt.xticks(fontsize=18)                 \n",
    "plt.yticks(fontsize=18) \n",
    "\n",
    "# Añadir leyenda\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right', fontsize=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.title('Marea Pichidangui (july 2023-september 2024)', fontsize=20) # titulo\n",
    "plt.show() # Mostrar figura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d8a68f2b-f42b-4d62-ada6-d62f2fc78959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los residuos\n",
    "#plt.xlabel('Fecha', fontsize=20) # Label de x\n",
    "plt.ylabel('Residuo [m]', fontsize=20) # Label de y\n",
    "plt.plot(t, u-tide.h, color='yellowgreen', label='Nivel de los Residuos [m]') # Ploteo de datos\n",
    "plt.xticks(fontsize=18)                 \n",
    "plt.yticks(fontsize=18) \n",
    "\n",
    "# Añadir leyenda\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right', fontsize=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.title('Residuos Pichidangui (july 2023-september 2024)', fontsize=20) # titulo\n",
    "plt.show() # Mostrar figura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f777dd1-9f9b-4ca3-827e-f4df6ad5adaf",
   "metadata": {},
   "source": [
    "## Análisis de mareas altas y bajas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef8f8c8f-856d-4a26-a8b8-a63152fe001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marib\\AppData\\Local\\Temp\\ipykernel_12888\\108663410.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv_filtered['Media movil 30min'] = csv_filtered['prs(m)'].rolling(30).mean()\n",
      "C:\\Users\\marib\\AppData\\Local\\Temp\\ipykernel_12888\\108663410.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv_filtered['Smooth Media Movil 30min'] = Smoot_Media_mov_joint\n"
     ]
    }
   ],
   "source": [
    "# Primero calculamos la media movil para un rango de 30 min (suavizado de datos):\n",
    "csv_filtered['Media movil 30min'] = csv_filtered['prs(m)'].rolling(30).mean()\n",
    "# Exportamos un filtro para suavizar aun mas los datos\n",
    "from scipy.signal import savgol_filter\n",
    "Media_mov = np.split(np.array(csv_filtered['Media movil 30min']), [29]) # Vector de media movil\n",
    "Smoot_Media_mov = savgol_filter(Media_mov[1], 500, 5)                   # Media movil suavizada\n",
    "#Incorporamos la curva suavizada al dataframe\n",
    "Smoot_Media_mov_joint = np.concatenate((Media_mov[0],Smoot_Media_mov), axis=0)\n",
    "csv_filtered['Smooth Media Movil 30min'] = Smoot_Media_mov_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b79d083-40f1-4cdb-858e-509c94514219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos análisis de señales en los datos suavizados\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Encontrar peaks (local maxima)\n",
    "peaks, _ = find_peaks(csv_filtered['Smooth Media Movil 30min'], height=0)\n",
    "\n",
    "# Encontrar valles local minima)\n",
    "valleys, _ = find_peaks(-np.array(csv_filtered['Smooth Media Movil 30min']), height=None)\n",
    "\n",
    "# Guardar los tiempos de los peaks y valles\n",
    "peak_times = csv_filtered['fecha'].iloc[peaks].values\n",
    "valley_times = csv_filtered['fecha'].iloc[valleys].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d76c42-f3c7-4f70-95e3-c1faebb9dcb0",
   "metadata": {},
   "source": [
    "### Debido a la media móvil los tiempos de máximos y mínimos se encuentran defasados. Procedemos a encontrar los máximos y mínimos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8519e50-89ae-4e54-85cb-228f3ecb11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir peak_times y valley_times en dataframes\n",
    "df_peak_times = pd.DataFrame({\n",
    "    'fecha': peak_times\n",
    "})\n",
    "df_valley_times = pd.DataFrame({\n",
    "    'fecha': valley_times\n",
    "})\n",
    "\n",
    "# Parámetros del rango temporal \n",
    "time_window = pd.Timedelta(minutes=180)\n",
    "\n",
    "# Función para encontrar máximos del rango temporal alrededor de cada peak y mínimo en valle\n",
    "# df_numeric -> Datos originales\n",
    "# peaks_t -> tiempos de los peaks suavizados\n",
    "# window -> Ventana de tiempo donde buscar los verdaderos peaks\n",
    "# inverted -> Busca valles\n",
    "def find_max_in_window(df_numeric, peaks_t, window, inverted = False):\n",
    "    # Filtrar el DataFrame numérico dentro del rango temporal\n",
    "    mask = (df_numeric['fecha'] >= (peaks_t - window)) & (df_numeric['fecha'] <= (peaks_t + window))\n",
    "    filtered_df = df_numeric[mask]\n",
    "    \n",
    "    # Encontrar el valor máximo y su fecha en datetime (lo mismo para valles)\n",
    "    if not filtered_df.empty:\n",
    "        if inverted == False:\n",
    "            max_value = filtered_df['prs(m)'].max()\n",
    "            max_time = filtered_df.loc[filtered_df['prs(m)'].idxmax(), 'fecha']\n",
    "            return max_value, max_time\n",
    "        else:\n",
    "            min_value = filtered_df['prs(m)'].min()\n",
    "            min_time = filtered_df.loc[filtered_df['prs(m)'].idxmin(), 'fecha']\n",
    "            return min_value, min_time\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Aplicar la función a cada peak del DataFrame 1\n",
    "results_peaks = []\n",
    "for index, row in df_peak_times.iterrows():\n",
    "    timestamp = row['fecha']\n",
    "    max_value, max_time = find_max_in_window(csv_filtered, timestamp, time_window)\n",
    "    results_peaks.append({'HT peak (m)': max_value, 'real peak time': max_time})\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "df_results_HT = pd.DataFrame(results_peaks)\n",
    "\n",
    "# Aplicar la función a cada peak del DataFrame 1\n",
    "results_valleys = []\n",
    "for index, row in df_valley_times.iterrows():\n",
    "    timestamp = row['fecha']\n",
    "    min_value, min_time = find_max_in_window(csv_filtered, timestamp, time_window, inverted = True)\n",
    "    results_valleys.append({'LT valley (m)': min_value, 'real valley time': min_time})\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "df_results_LT = pd.DataFrame(results_valleys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "df8f96e8-6ce7-406b-afbe-8d533a918f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos si los tiempos de los peaks coinciden con los datos reales\n",
    "plt.plot(csv_filtered['fecha'], csv_filtered['prs(m)'], label= 'NM [m]', color = 'black', linewidth = 2)\n",
    "plt.ylabel('Nivel del Mar [m]', fontsize=24) # Label de y\n",
    "plt.xticks(fontsize=18)                 \n",
    "plt.yticks(fontsize=22) \n",
    "plt.scatter(df_results_HT['real peak time'], df_results_HT['HT peak (m)'], label='Marea Alta', color = 'yellowgreen', linewidths = 8)\n",
    "plt.scatter(df_results_LT['real valley time'], df_results_LT['LT valley (m)'], label='Marea Baja', color = 'slateblue', linewidths = 8)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5ac02f77-361d-486d-804d-20a287a37e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot de High and Low tide\n",
    "plt.ylabel('Nivel del Mar [m]', fontsize=24) # Label de y\n",
    "plt.xticks(fontsize=18)                 \n",
    "plt.yticks(fontsize=22) \n",
    "plt.plot(df_results_HT['real peak time'], df_results_HT['HT peak (m)'], label='Marea Alta', color = 'yellowgreen', linewidth = 3)\n",
    "plt.plot(df_results_LT['real valley time'], df_results_LT['LT valley (m)'], label='Marea Baja', color = 'slateblue', linewidth = 3)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c700f-f5f4-458f-a17d-24e839f4956a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
